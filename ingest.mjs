// ingest.mjs
import 'dotenv/config';
import fs from 'fs/promises';
import path from 'path';
import { glob } from 'glob';
import { fileURLToPath } from 'url';
// ‚¨áÔ∏è LangChain 0.3 Í≤ΩÎ°ú Î≥ÄÍ≤Ω
import { RecursiveCharacterTextSplitter } from '@langchain/textsplitters';
import { Document } from '@langchain/core/documents';

// ‚¨áÔ∏è Ollama Embeddings Ìå®ÌÇ§ÏßÄ Î∂ÑÎ¶¨
import { OllamaEmbeddings } from '@langchain/ollama';

// LanceDB
import { connect } from '@lancedb/lancedb';


const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);


const DATA_DIR = path.join(__dirname, 'university-data');
const DB_DIR = path.join(__dirname, 'vectorstore');
const TABLE_NAME = 'uni_docs';


const CHUNK_SIZE = parseInt(process.env.CHUNK_SIZE ?? '1000', 10);
const CHUNK_OVERLAP = parseInt(process.env.CHUNK_OVERLAP ?? '150', 10);


// --- Embeddings ÏÑ†ÌÉù: (Í∏∞Î≥∏) Ollama ---
const embeddings = new OllamaEmbeddings({ model: process.env.EMBEDDING_MODEL || 'nomic-embed-text' });


// // --- Embeddings ÏÑ†ÌÉù: OpenAI (ÏõêÌïòÎ©¥ Ïù¥ ÎùºÏù∏Îì§Î°ú ÍµêÏ≤¥)
// const embeddings = new OpenAIEmbeddings({
// model: process.env.OPENAI_EMBEDDING_MODEL || 'text-embedding-3-small',
// apiKey: process.env.OPENAI_API_KEY,
// });


async function loadTextFiles(dir) {
const patterns = ['**/*.md', '**/*.txt']; // ÌïÑÏöî Ïãú ÌôïÏû•: pdf/docx Î°úÎçî ÏÇ¨Ïö©
const files = patterns.flatMap((p) => glob.sync(path.join(dir, p)));
const docs = [];
for (const file of files) {
const text = await fs.readFile(file, 'utf8');
docs.push(new Document({ pageContent: text, metadata: { source: path.relative(dir, file) } }));
}
return docs;
}


async function main() {
console.log('üîé Loading docs from:', DATA_DIR);
const rawDocs = await loadTextFiles(DATA_DIR);
if (rawDocs.length === 0) {
console.log('‚ö†Ô∏è No documents found in university-data/. Add .md or .txt files.');
return;
}


const splitter = new RecursiveCharacterTextSplitter({
chunkSize: CHUNK_SIZE,
chunkOverlap: CHUNK_OVERLAP,
separators: ['\n\n', '\n', ' ', '']
});


const chunks = await splitter.splitDocuments(rawDocs);
console.log(`‚úÇÔ∏è Split into ${chunks.length} chunks (size=${CHUNK_SIZE}, overlap=${CHUNK_OVERLAP})`);


// LanceDB Ïó∞Í≤∞ Î∞è ÌÖåÏù¥Î∏î Ï§ÄÎπÑ
const db = await connect(DB_DIR);
const tableNames = await db.tableNames();

let table = null;
let created = tableNames.includes(TABLE_NAME);
if (created) {
  table = await db.openTable(TABLE_NAME);
}

// --- ÏûÑÎ≤†Îî© Í≥ÑÏÇ∞ ÌõÑ upsert ---
console.log('üß† Computing embeddings & upserting...');

const batchSize = 64;
for (let i = 0; i < chunks.length; i += batchSize) {
  const batch = chunks.slice(i, i + batchSize);
  const texts = batch.map((d) => d.pageContent);

  // ÏûÑÎ≤†Îî© Í≥ÑÏÇ∞
  const vectors = await embeddings.embedDocuments(texts);

  // LanceDB row Ìè¨Îß∑
const rows = batch.map((doc, idx) => ({
  id: `${doc.metadata.source}::${i + idx}`,
  text: doc.pageContent,
  source: doc.metadata.source,
  vector: vectors[idx], // LanceDB Í∏∞Î≥∏ Ïª¨ÎüºÎ™Ö
}));

if (!created) {
  table = await db.createTable(TABLE_NAME, rows);
  created = true;
} else {
  await table.add(rows);
}

  process.stdout.write(`\r‚úÖ Upserted ${Math.min(i + batchSize, chunks.length)} / ${chunks.length}`);
}
console.log('\nüéâ Ingestion complete!');
}

main().catch((e) => {
console.error(e);
process.exit(1);
});
